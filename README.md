Formula 1 Data Pipeline ğŸš€

Azure Databricks | Medallion Architecture | Delta Lake

ğŸ“Œ Overview
This project builds a Formula 1 Data Pipeline in Azure Databricks, using Delta Lake and the Medallion Architecture (Bronze, Silver, Gold). The pipeline processes, 
transforms, and analyzes Formula 1 racing data.

ğŸ“‚ Project Structure
Formula1-Data-Pipeline/
â”‚â”€â”€ notebooks/                  # Jupyter Notebooks for each pipeline stage
â”‚â”€â”€ data/                        # Raw datasets (JSON, CSV, Parquet)
â”‚â”€â”€ configs/                     # Configuration files (parameters, secrets)
â”‚â”€â”€ sql_queries/                 # SQL scripts for transformations
â”‚â”€â”€ scripts/                     # Python/PySpark scripts
â”‚â”€â”€ docs/                        # Documentation & PPT
â”‚   â”œâ”€â”€ project_requirements.pptx  # Requirements document
â”‚â”€â”€ .gitignore                    # Ignore unnecessary files
â”‚â”€â”€ requirements.txt              # Python dependencies
â”‚â”€â”€ LICENSE                       # Project license
â”‚â”€â”€ README.md                     # Documentation (You're here!)


ğŸ›  ï¸ Tech Stack
Cloud: Microsoft Azure
Compute: Databricks
Storage: Azure Data Lake Storage (ADLS)
Processing: PySpark, Delta Lake
Database: Databricks SQL
Orchestration: Databricks Jobs

ğŸ— ï¸ Data Pipeline Architecture
This project follows the Medallion Architecture to structure data efficiently.

1ï¸âƒ£  Bronze Layer (Raw Data)
Stores raw JSON/CSV data in ADLS.
No transformations, only ingestion.
Data is partitioned by date.

2ï¸âƒ£  Silver Layer (Processed Data)
Cleans and transforms raw data.
Standardizes column names and removes duplicates.
Joins multiple sources to create meaningful datasets.

3ï¸âƒ£  Gold Layer (Aggregated Data)
Prepares final tables for reporting.
Includes aggregations like driver standings & constructor standings.
Optimized for analytics (stored in Delta format).

ğŸ“Š Data Sources
Formula 1 Standings Data
Race Results & Constructors Data

âš™ï¸ Setup & Installation

1ï¸âƒ£  Clone  the Repository
git clone https://github.com/your-username/Formula1-Data-Pipeline.git
cd Formula1-Data-Pipeline

2ï¸âƒ£  Create  a Virtual Environment
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows

3ï¸âƒ£  Upload  Notebooks to Databricks

1. Open Azure Databricks.
2. Navigate to Workspace â†’ Create Folder â†’ Formula1-Data-Pipeline.
3. Upload notebooks/ inside the folder.
4. Attach to a Databricks cluster and run.


ğŸš€ Running the Pipeline
1. Bronze Layer:
	Run the notebook to ingest raw data into ADLS (Azure Data Lake Storage).

2. Silver Layer:
	Clean, standardize & join tables.

3. Gold Layer:
	Perform aggregations (standings, race results).
	Run SQL Queries for insights.


ğŸ“Œ Best Practices
Use Delta Lake for ACID transactions.
Optimize with ZORDER & OPTIMIZE commands.
Implement Data Quality Checks in Silver Layer.
Automate Orchestration using Databricks Jobs


ğŸ“œ License
This project is open-source under the MIT License.


ğŸ’¡ Contributing
Want to improve this pipeline? Follow these steps:

Fork the repo.
Create a new branch (feature-new).
Commit your changes.
Submit a PR.


â­ If you found this useful, give it a star on GitHub! â­
